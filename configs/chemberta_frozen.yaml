name: "chemberta_frozen"

model:
  type: "ChemBERTa"
  pretrained_model: "seyonec/ChemBERTa-zinc-base-v1"
  freeze_encoder: true  # Only train prediction head
  dropout: 0.2

data:
  featurizer: "smiles_text"

training:
  lr: 0.001  # Higher LR since only training small head
  batch_size: 32
  max_epochs: 20
  patience: 10
  weight_decay: 0.0
  seed: 42